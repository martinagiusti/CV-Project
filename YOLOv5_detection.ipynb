{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c281184-c22e-4e98-a668-b717c2f1a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt  # Visualizzazione grafici e immagini\n",
    "import numpy as np               # Operazioni numeriche su array multidimensionali\n",
    "import os                       # Interazione con il sistema operativo (file, cartelle)\n",
    "import pandas as pd             # Manipolazione e analisi di dati tabellari (DataFrame)\n",
    "import random                   # Funzioni per generazione di numeri casuali\n",
    "import sys                      # Funzioni per interagire con l'ambiente di esecuzione Python\n",
    "import torch                    # Libreria principale di deep learning PyTorch (tensori, GPU)\n",
    "import torch.nn as nn           # Costruzione modelli di reti neurali con layer predefiniti\n",
    "import torch.nn.functional as F # Funzioni utili come attivazioni, loss, pooling\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from fvcore.nn import FlopCountAnalysis  # Analisi di FLOPS e complessita' computazionale della rete\n",
    "from IPython.display import display       # Visualizzazione ricca di output (notebook Jupyter)\n",
    "from PIL import Image, ImageDraw, ImageFont   # Manipolazione e caricamento immagini\n",
    "from torch.utils.data import Dataset, DataLoader  # Gestione dataset personalizzati e batching\n",
    "from torchvision import transforms       # Trasformazioni e preprocessamento immagini\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms.functional import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd56421-08d1-430a-bd7e-081b537c879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(torch.version.cuda)  # Es: '12.1'\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcbb94-b680-4c84-bfdb-494f554f4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso locale al dataset\n",
    "dataset_path = 'CCPD2019' \n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Dataset trovato in locale!\")\n",
    "else:\n",
    "    print(f\"Dataset non trovato al percorso: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f2804-c5b6-4f00-9f96-c46fd3ac61b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directory_tree_jpg_png_limited(path, prefix=\"\", is_last=True, max_image_files=5, is_root=False):\n",
    "    \"\"\"\n",
    "    Stampa ricorsivamente la struttura ad albero di una directory, mostrando sottocartelle e file.\n",
    "    \n",
    "    Per i file immagine con estensione .jpg o .png limita la stampa ai primi `max_image_files` file,\n",
    "    aggiungendo \"...\" se ce ne sono di piu'.\n",
    "    \n",
    "    Parametri:\n",
    "    - path (str): percorso della directory da esplorare.\n",
    "    - prefix (str): prefisso usato per l'indentazione (usato internamente nella ricorsione).\n",
    "    - is_last (bool): indica se l'elemento corrente e' l'ultimo nella lista (per disegnare correttamente i connettori).\n",
    "    - max_image_files (int): numero massimo di file immagine (.jpg, .png) da mostrare per ogni cartella.\n",
    "    - is_root (bool): se True stampa solo il nome della cartella root senza prefisso.\n",
    "    \"\"\"\n",
    "\n",
    "    connector = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "\n",
    "    if is_root:\n",
    "        print(path)\n",
    "    else:\n",
    "        print(prefix + connector + os.path.basename(path))\n",
    "\n",
    "    new_prefix = prefix + (\"    \" if is_last else \"‚îÇ   \")\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        items = sorted(os.listdir(path))\n",
    "        full_paths = [os.path.join(path, item) for item in items]\n",
    "\n",
    "        dirs = [item for item in full_paths if os.path.isdir(item)]\n",
    "        files = [item for item in full_paths if os.path.isfile(item)]\n",
    "\n",
    "        # Stampa tutte le sottocartelle\n",
    "        for i, d in enumerate(dirs):\n",
    "            is_last_dir = (i == len(dirs) - 1 and not files)\n",
    "            print_directory_tree_jpg_png_limited(d, new_prefix, is_last_dir, max_image_files)\n",
    "\n",
    "        # Se la cartella contiene immagini jpg o png, limita la stampa\n",
    "        image_files = [f for f in files if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "        if image_files:\n",
    "            limited_images = image_files[:max_image_files]\n",
    "            if len(image_files) > max_image_files:\n",
    "                limited_images.append(\"...\")\n",
    "\n",
    "            for i, f in enumerate(limited_images):\n",
    "                is_last_file = i == len(limited_images) - 1\n",
    "                if f == \"...\":\n",
    "                    print(new_prefix + \"‚îî‚îÄ‚îÄ ...\")\n",
    "                else:\n",
    "                    print(new_prefix + (\"‚îî‚îÄ‚îÄ \" if is_last_file else \"‚îú‚îÄ‚îÄ \") + os.path.basename(f))\n",
    "        else:\n",
    "            # Altri file (non jpg o png): mostrali tutti\n",
    "            for i, f in enumerate(files):\n",
    "                is_last_file = i == len(files) - 1\n",
    "                print(new_prefix + (\"‚îî‚îÄ‚îÄ \" if is_last_file else \"‚îú‚îÄ‚îÄ \") + os.path.basename(f))\n",
    "\n",
    "print(\"CCPD - Directory Tree:\\n\")\n",
    "print_directory_tree_jpg_png_limited(dataset_path, is_root=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae631945-cb68-49ce-8c50-5438295bd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per leggere e mostrare le prime righe di un file txt\n",
    "def show_txt_head(txt_file, num_lines=5):\n",
    "    \"\"\"\n",
    "    Mostra le prime `num_lines` righe di un file di testo.\n",
    "\n",
    "    Parametri:\n",
    "    - txt_file (str): percorso del file di testo da leggere.\n",
    "    - num_lines (int): numero di righe da visualizzare (default e' 5).\n",
    "\n",
    "    La funzione apre il file in modalita' lettura, stampa riga per riga\n",
    "    fino al numero specificato o fino alla fine del file.\n",
    "    \"\"\"\n",
    "    print(f\"Prime {num_lines} righe di {txt_file}:\")\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for _ in range(num_lines):\n",
    "            line = f.readline().strip()\n",
    "            if not line:\n",
    "                break\n",
    "            print(line)\n",
    "    print()  # Riga vuota per separare le uscite\n",
    "\n",
    "# Percorsi ai file txt di train, validation e test\n",
    "train_txt_path = os.path.join(dataset_path, 'splits', 'train.txt')\n",
    "val_txt_path = os.path.join(dataset_path, 'splits', 'val.txt')\n",
    "test_txt_path = os.path.join(dataset_path, 'splits', 'test.txt')\n",
    "\n",
    "# Mostra prime righe dei file train, val e test\n",
    "show_txt_head(train_txt_path, num_lines=5)\n",
    "show_txt_head(val_txt_path, num_lines=5)\n",
    "show_txt_head(test_txt_path, num_lines=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd11f72-48a9-4c9a-8e81-4859f5acf049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_first_existing_ccpd_sample(txt_file, dataset_path, title=\"Sample\"):\n",
    "    \"\"\"\n",
    "    Cerca e mostra la prima immagine elencata in un file di testo.\n",
    "\n",
    "    Parametri:\n",
    "    - txt_file (str): percorso al file di testo che contiene i percorsi relativi delle immagini.\n",
    "    - dataset_path (str): percorso alla cartella radice del dataset.\n",
    "    - title (str): titolo da visualizzare sopra l'immagine (default: \"Sample\").\n",
    "\n",
    "    La funzione legge tutte le righe del file txt, costruisce i percorsi completi\n",
    "    delle immagini unendo il dataset_path con i percorsi relativi, e cerca la prima immagine\n",
    "    che esiste sul disco. Se la trova, la apre e la mostra con matplotlib.\n",
    "    Se nessuna immagine valida viene trovata, stampa un messaggio di avviso.\n",
    "    \"\"\"\n",
    "    # Legge tutte le righe dal file txt\n",
    "    with open(txt_file, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    # Cerca la prima immagine esistente\n",
    "    for idx, img_rel_path in enumerate(lines):\n",
    "        img_path = os.path.join(dataset_path, img_rel_path)\n",
    "        if os.path.isfile(img_path):\n",
    "            # Apre e mostra l'immagine\n",
    "            img = Image.open(img_path)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"{title} - Immagine indice {idx}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            return  # Esce dopo aver mostrato la prima immagine valida\n",
    "    \n",
    "    print(f\"Nessuna immagine trovata valida in {txt_file}\")\n",
    "\n",
    "\n",
    "# Mostra la prima immagine valida da train, val e test\n",
    "show_first_existing_ccpd_sample(train_txt_path, dataset_path, title=\"Training Sample\")\n",
    "show_first_existing_ccpd_sample(val_txt_path, dataset_path, title=\"Validation Sample\")\n",
    "show_first_existing_ccpd_sample(test_txt_path, dataset_path, title=\"Test Sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b7e50-fbfd-4e35-9d26-05790ddee9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi intero dataset (non eseguire)\n",
    "\n",
    "def inspect_image(image_path):\n",
    "    \"\"\"\n",
    "    Apre un'immagine e ne estrae informazioni chiave.\n",
    "\n",
    "    Parametri:\n",
    "    - image_path (str): percorso completo dell'immagine da analizzare.\n",
    "\n",
    "    Restituisce:\n",
    "    - dict con informazioni sull'immagine:\n",
    "      - \"mode\": modalita' colore (es. 'RGB', 'L', ecc.)\n",
    "      - \"dtype\": tipo di dato dei pixel (es. 'uint8')\n",
    "      - \"shape\": dimensioni dell'immagine (altezza, larghezza, canali)\n",
    "      - \"min\": valore minimo dei pixel\n",
    "      - \"max\": valore massimo dei pixel\n",
    "    - None se l'immagine non puo' essere aperta o e' corrotta.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        arr = np.array(img)\n",
    "        return {\n",
    "            \"mode\": img.mode,\n",
    "            \"dtype\": str(arr.dtype),\n",
    "            \"shape\": arr.shape,\n",
    "            \"min\": arr.min(),\n",
    "            \"max\": arr.max()\n",
    "        }\n",
    "    except Exception:\n",
    "        # Gestione silenziosa degli errori\n",
    "        return None\n",
    "\n",
    "\n",
    "def inspect_txt_images(txt_path, data_path, name=\"\"):\n",
    "    \"\"\"\n",
    "    Analizza un insieme di immagini elencate in un file di testo e stampa statistiche aggregate.\n",
    "\n",
    "    Parametri:\n",
    "    - txt_path (str): percorso al file di testo contenente i percorsi relativi delle immagini.\n",
    "    - data_path (str): percorso alla cartella radice del dataset.\n",
    "    - name (str): nome descrittivo del dataset (es. 'Training Set') per stampa a video.\n",
    "\n",
    "    Funzionamento:\n",
    "    - Legge tutte le righe del file txt.\n",
    "    - Per ogni immagine valida (leggibile), estrae informazioni tramite inspect_image.\n",
    "    - Conta e stampa quante immagini sono analizzate e statistiche su modalita' colore,\n",
    "      tipo dati e dimensioni delle immagini.\n",
    "    - Ignora silenziosamente immagini non trovate o corrotte.\n",
    "    \"\"\"\n",
    "    print(f\"\\n Analisi del dataset: {name}\")\n",
    "    \n",
    "    # Legge tutte le righe (percorsi immagini)\n",
    "    with open(txt_path, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    stats = defaultdict(Counter)\n",
    "    valid_count = 0\n",
    "\n",
    "    for rel_path in lines:\n",
    "        abs_path = os.path.join(data_path, rel_path)\n",
    "        info = inspect_image(abs_path)\n",
    "\n",
    "        if info is None:\n",
    "            # Ignora silenziosamente immagini non trovate o corrotte\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "        stats[\"mode\"][info[\"mode\"]] += 1\n",
    "        stats[\"dtype\"][info[\"dtype\"]] += 1\n",
    "        stats[\"shape\"][str(info[\"shape\"])] += 1\n",
    "\n",
    "    print(f\"Immagini analizzate: {valid_count} su {len(lines)}\")\n",
    "    print(f\"\\n Statistiche immagini per dataset '{name}':\")\n",
    "\n",
    "    print(\"Mode:\", dict(stats[\"mode\"]))\n",
    "    print(\"Dtype:\", dict(stats[\"dtype\"]))\n",
    "    print(\"Shape:\", dict(stats[\"shape\"]))\n",
    "\n",
    "\n",
    "inspect_txt_images(train_txt_path, dataset_path, name=\"Training Set\")\n",
    "inspect_txt_images(val_txt_path, dataset_path, name=\"Validation Set\")\n",
    "inspect_txt_images(test_txt_path, dataset_path, name=\"Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ae657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_plate(plate_str):\n",
    "    provinces = [\"Áöñ\", \"Ê≤™\", \"Ê¥•\", \"Ê∏ù\", \"ÂÜÄ\", \"Êôã\", \"Ëíô\", \"ËæΩ\", \"Âêâ\", \"Èªë\", \"Ëãè\", \"Êµô\", \"‰∫¨\",\n",
    "                 \"ÈóΩ\", \"Ëµ£\", \"È≤Å\", \"Ë±´\", \"ÈÑÇ\", \"Êπò\", \"Á≤§\", \"Ê°Ç\", \"Áêº\", \"Â∑ù\", \"Ë¥µ\", \"‰∫ë\", \"Ëóè\",\n",
    "                 \"Èôï\", \"Áîò\", \"Èùí\", \"ÂÆÅ\", \"Êñ∞\", \"Ë≠¶\", \"Â≠¶\", \"O\"]\n",
    "    alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P',\n",
    "                 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
    "    ads = alphabets + [str(d) for d in range(10)] + ['O']\n",
    "    \n",
    "    indices = list(map(int, plate_str.split('_')))\n",
    "    prov = provinces[indices[0]] if indices[0] < len(provinces) else 'O'\n",
    "    alpha = alphabets[indices[1]] if indices[1] < len(alphabets) else 'O'\n",
    "    ads_str = ''.join(ads[i] if i < len(ads) else 'O' for i in indices[2:])\n",
    "    return prov + alpha + ads_str\n",
    "\n",
    "def parse_filename(filename):\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    parts = name.split('-', maxsplit=6)\n",
    "    if len(parts) != 7:\n",
    "        raise ValueError(f\"Filename non conforme: {filename}\")\n",
    "    \n",
    "    bbox = None\n",
    "    vertices = None\n",
    "\n",
    "    try:\n",
    "        leftup_str, rightdown_str = parts[2].split('_')\n",
    "        x_min, y_min = map(int, leftup_str.split('&'))\n",
    "        x_max, y_max = map(int, rightdown_str.split('&'))\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        vertices = [list(map(int, v.split('&'))) for v in parts[3].split('_')]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    plate_str = parts[4]\n",
    "    annotation = decode_plate(plate_str)\n",
    "    encoded_label = list(map(int, plate_str.split('_')))  # üî• nuovo formato usabile direttamente\n",
    "\n",
    "    brightness = int(parts[5]) if parts[5].isdigit() else None\n",
    "    blurriness = int(parts[6]) if parts[6].isdigit() else None\n",
    "\n",
    "    return {\n",
    "        'area': parts[0],\n",
    "        'tilt': parts[1],\n",
    "        'bbox': bbox,\n",
    "        'vertices': vertices,\n",
    "        'annotation': annotation,\n",
    "        'encoded_label': encoded_label,\n",
    "        'brightness': brightness,\n",
    "        'blurriness': blurriness\n",
    "    }\n",
    "\n",
    "def create_csv_from_txt(txt_path, dataset_path, csv_output_path):\n",
    "    with open(txt_path, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    data = []\n",
    "    for rel_path in lines:\n",
    "        filename = os.path.basename(rel_path)\n",
    "        try:\n",
    "            parsed = parse_filename(filename)\n",
    "            data.append({\n",
    "                'image_path': rel_path,\n",
    "                'area': parsed['area'],\n",
    "                'tilt': parsed['tilt'],\n",
    "                'bbox': parsed['bbox'],\n",
    "                'vertices': parsed['vertices'],\n",
    "                'annotation': parsed['annotation'],\n",
    "                'encoded_label': parsed['encoded_label'],\n",
    "                'brightness': parsed['brightness'],\n",
    "                'blurriness': parsed['blurriness']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Errore parsing {filename}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "    print(f\" CSV salvato: {csv_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0113d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_from_txt(train_txt_path, dataset_path, 'train.csv')\n",
    "create_csv_from_txt(val_txt_path, dataset_path, 'val.csv')\n",
    "create_csv_from_txt(test_txt_path, dataset_path, 'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065baf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_files_to_test(txt_path, source_path, category_name=None):\n",
    "    \"\"\"\n",
    "    Aggiunge i file contenuti in source_path al file test.txt con prefisso 'category_name/'.\n",
    "    \n",
    "    Parametri:\n",
    "    - txt_path: path al test.txt\n",
    "    - source_path: cartella da cui leggere i file\n",
    "    - category_name: nome prefisso (se None usa nome cartella finale)\n",
    "    \"\"\"\n",
    "    if category_name is None:\n",
    "        category_name = os.path.basename(os.path.normpath(source_path))\n",
    "\n",
    "    files = [f for f in os.listdir(source_path) if os.path.isfile(os.path.join(source_path, f))]\n",
    "    print(f\" Trovati {len(files)} file in {source_path}\")\n",
    "\n",
    "    with open(txt_path, 'a') as f:\n",
    "        for file_name in files:\n",
    "            relative_path = f\"{category_name}/{file_name}\"\n",
    "            f.write(relative_path + '\\n')\n",
    "\n",
    "    print(f\" Aggiunti {len(files)} file a {txt_path}\")\n",
    "\n",
    "append_files_to_test('test.txt', '.\\\\CCPD2019\\\\ccpd_weather')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_path = os.path.join(dataset_path, 'splits', 'test.txt')\n",
    "create_csv_from_txt(test_txt_path, dataset_path, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bf651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_drawing(image_path):\n",
    "    \"\"\"\n",
    "    Apre un'immagine e prepara un oggetto per disegnare su di essa.\n",
    "\n",
    "    Parametri:\n",
    "    - image_path (str): percorso dell'immagine da aprire.\n",
    "\n",
    "    Restituisce:\n",
    "    - img (PIL.Image): immagine aperta.\n",
    "    - draw (ImageDraw.Draw): oggetto per disegnare sull'immagine.\n",
    "\n",
    "    Se l'apertura fallisce, stampa un messaggio di errore e restituisce (None, None).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        return img, draw\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'apertura dell'immagine {image_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def draw_bbox(draw, bbox, outline='red', width=6):\n",
    "    \"\"\"\n",
    "    Disegna una bounding box rettangolare sull'immagine.\n",
    "\n",
    "    Parametri:\n",
    "    - draw (ImageDraw.Draw): oggetto per disegno.\n",
    "    - bbox (list o tuple): lista o tupla con coordinate [x_min, y_min, x_max, y_max].\n",
    "    - outline (str): colore del bordo del rettangolo (default 'red').\n",
    "    - width (int): spessore del bordo (default 6).\n",
    "\n",
    "    Se bbox e' None, non viene disegnato nulla.\n",
    "    \"\"\"\n",
    "    if bbox:\n",
    "        draw.rectangle(bbox, outline=outline, width=width)\n",
    "\n",
    "def draw_overlay_label(draw, annotation, bbox):\n",
    "    \"\"\"\n",
    "    Disegna l'annotazione come testo sopra il bounding box con sfondo nero.\n",
    "\n",
    "    Parametri:\n",
    "    - draw (ImageDraw.Draw): oggetto per disegno.\n",
    "    - annotation (str): testo da mostrare (es. targa).\n",
    "    - bbox (list o tuple): coordinate del bounding box [x_min, y_min, x_max, y_max].\n",
    "\n",
    "    Il testo viene disegnato in giallo con uno sfondo nero rettangolare\n",
    "    posizionato subito sopra il bounding box.\n",
    "    \"\"\"\n",
    "    if annotation and bbox:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "        # Font di default\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "        # Calcola dimensione del testo\n",
    "        bbox_text = draw.textbbox((0, 0), annotation, font=font)\n",
    "        text_width = bbox_text[2] - bbox_text[0]\n",
    "        text_height = bbox_text[3] - bbox_text[1]\n",
    "\n",
    "\n",
    "        # Coordinate del rettangolo di sfondo (leggermente pi√π grande del testo)\n",
    "        background_bbox = [x_min, y_min - text_height - 4, x_min + text_width + 4, y_min]\n",
    "\n",
    "        # Disegna sfondo nero\n",
    "        draw.rectangle(background_bbox, fill='black')\n",
    "\n",
    "        # Disegna testo giallo sopra lo sfondo\n",
    "        draw.text((x_min + 2, y_min - text_height - 2), annotation, fill='yellow', font=font)\n",
    "\n",
    "def show_image_with_bbox_and_annotation(image_path, bbox, annotation):\n",
    "    \"\"\"\n",
    "    Apre un'immagine, disegna bounding box e annotazione, e la mostra con matplotlib.\n",
    "\n",
    "    Parametri:\n",
    "    - image_path (str): percorso dell'immagine.\n",
    "    - bbox (list o tuple): coordinate del bounding box.\n",
    "    - annotation (str): testo dell'annotazione da disegnare.\n",
    "\n",
    "    Se l'immagine non si apre, non mostra nulla.\n",
    "    \"\"\"\n",
    "    img, draw = prepare_image_drawing(image_path)\n",
    "    if img is None:\n",
    "        return\n",
    "    \n",
    "    draw_bbox(draw, bbox, outline='red', width=6)\n",
    "    draw_overlay_label(draw, annotation, bbox)\n",
    "    \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_two_examples_from_csv_using_bbox(csv_path, dataset_path, n=2):\n",
    "    \"\"\"\n",
    "    Mostra i primi n esempi di immagini con bounding box e annotazione letti da un file CSV.\n",
    "\n",
    "    Parametri:\n",
    "    - csv_path (str): percorso del file CSV contenente i dati delle immagini.\n",
    "    - dataset_path (str): percorso della cartella radice del dataset.\n",
    "    - n (int): numero di esempi da mostrare (default 2).\n",
    "\n",
    "    Per ogni immagine nel CSV, apre l'immagine, estrae il bounding box e l'annotazione,\n",
    "    e mostra l'immagine con i relativi disegni.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    for idx, row in df.head(n).iterrows():\n",
    "        rel_path = row['image_path']\n",
    "        abs_path = os.path.join(dataset_path, rel_path)\n",
    "        \n",
    "        try:\n",
    "            bbox = ast.literal_eval(row['bbox']) if pd.notna(row['bbox']) else None\n",
    "        except Exception:\n",
    "            bbox = None\n",
    "        \n",
    "        annotation = row['annotation'] if 'annotation' in row else None\n",
    "        \n",
    "        print(f\"Mostro immagine: {rel_path}\")\n",
    "        show_image_with_bbox_and_annotation(abs_path, bbox, annotation)\n",
    "\n",
    "# Esempio di uso\n",
    "csv_path = 'train.csv' \n",
    "\n",
    "show_two_examples_from_csv_using_bbox(csv_path, dataset_path, n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd649d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloCCPDTransformCentered:\n",
    "    def __init__(self, dataset_path, size=(640, 640)):\n",
    "        \"\"\"\n",
    "        Inizializza la trasformazione.\n",
    "\n",
    "        Parametri:\n",
    "        - dataset_path (str): percorso della cartella radice del dataset.\n",
    "        - size (tuple): dimensione di output (altezza, larghezza), default (640, 640).\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.size = size  # (H, W)\n",
    "\n",
    "    def __call__(self, row):\n",
    "        \"\"\"\n",
    "        Applica la trasformazione a una singola riga del dataset.\n",
    "\n",
    "        Passaggi:\n",
    "        - Apre l'immagine dal percorso indicato.\n",
    "        - Calcola il bounding box della targa e il suo centro.\n",
    "        - Calcola il ritaglio quadrato massimo possibile centrato sulla targa,\n",
    "          che non esca dai bordi dell'immagine.\n",
    "        - Ritaglia l'immagine con questo quadrato.\n",
    "        - Aggiorna le coordinate del bounding box relativamente al ritaglio.\n",
    "        - Ridimensiona il crop all'output desiderato (self.size).\n",
    "        - Normalizza la bounding box nel formato YOLO (x_center, y_center, width, height).\n",
    "        \n",
    "        Parametri:\n",
    "        - row (pandas.Series o dict): riga del dataset con almeno i campi 'image_path' e 'bbox'.\n",
    "\n",
    "        Restituisce:\n",
    "        - dict con:\n",
    "            - 'image': tensore PyTorch dell'immagine ritagliata e ridimensionata.\n",
    "            - 'label': tensore PyTorch con la label [classe, x_center, y_center, width, height].\n",
    "        - None se l'immagine non esiste.\n",
    "        \"\"\"\n",
    "\n",
    "        image_path = os.path.join(self.dataset_path, row['image_path'])\n",
    "        if not os.path.isfile(image_path):\n",
    "            return None\n",
    "\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        orig_w, orig_h = image.size\n",
    "\n",
    "        bbox = row['bbox']\n",
    "        if isinstance(bbox, str):\n",
    "            bbox = ast.literal_eval(bbox)\n",
    "\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        box_w = x_max - x_min\n",
    "        box_h = y_max - y_min\n",
    "        box_cx = (x_min + x_max) / 2\n",
    "        box_cy = (y_min + y_max) / 2\n",
    "\n",
    "        # Calcola il ritaglio quadrato massimo possibile centrato sulla targa\n",
    "        dist_x = min(box_cx, orig_w - box_cx)\n",
    "        dist_y = min(box_cy, orig_h - box_cy)\n",
    "        half_side = min(dist_x, dist_y)\n",
    "\n",
    "        crop_xmin = int(box_cx - half_side)\n",
    "        crop_ymin = int(box_cy - half_side)\n",
    "        crop_xmax = int(box_cx + half_side)\n",
    "        crop_ymax = int(box_cy + half_side)\n",
    "\n",
    "        crop = image.crop((crop_xmin, crop_ymin, crop_xmax, crop_ymax))\n",
    "\n",
    "        # Aggiorna bbox relativa al crop\n",
    "        new_x_min = x_min - crop_xmin\n",
    "        new_y_min = y_min - crop_ymin\n",
    "        new_x_max = x_max - crop_xmin\n",
    "        new_y_max = y_max - crop_ymin\n",
    "\n",
    "        # Converti crop in tensore e ridimensiona\n",
    "        crop_tensor = TF.to_tensor(crop)\n",
    "        crop_h, crop_w = crop_tensor.shape[1:]\n",
    "        resized = TF.resize(crop_tensor, self.size, interpolation=Image.BILINEAR)\n",
    "\n",
    "        scale_x = self.size[1] / crop_w\n",
    "        scale_y = self.size[0] / crop_h\n",
    "\n",
    "        # Ridimensiona bbox\n",
    "        x_min_resized = new_x_min * scale_x\n",
    "        y_min_resized = new_y_min * scale_y\n",
    "        x_max_resized = new_x_max * scale_x\n",
    "        y_max_resized = new_y_max * scale_y\n",
    "\n",
    "        # Normalizza bbox (formato YOLO)\n",
    "        x_center = (x_min_resized + x_max_resized) / 2 / self.size[1]\n",
    "        y_center = (y_min_resized + y_max_resized) / 2 / self.size[0]\n",
    "        width = (x_max_resized - x_min_resized) / self.size[1]\n",
    "        height = (y_max_resized - y_min_resized) / self.size[0]\n",
    "\n",
    "        # Clipping di sicurezza\n",
    "        x_center = min(max(x_center, 0.0), 1.0)\n",
    "        y_center = min(max(y_center, 0.0), 1.0)\n",
    "        width = min(max(width, 0.0), 1.0)\n",
    "        height = min(max(height, 0.0), 1.0)\n",
    "        \n",
    "\n",
    "        label = [0, x_center, y_center, width, height]\n",
    "\n",
    "        return {\n",
    "            'image': resized,\n",
    "            'label': torch.tensor(label, dtype=torch.float32)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb492f73-1e68-425b-af9c-be2a3670a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ccpd_pair(df, dataset_path, transformer=None, title='Sample'):\n",
    "    \"\"\"\n",
    "    Visualizza un confronto tra l'immagine originale con bounding box e la sua versione trasformata.\n",
    "\n",
    "    Parametri:\n",
    "    - df (pandas.DataFrame): DataFrame contenente almeno le colonne 'image_path' e 'bbox'.\n",
    "    - dataset_path (str): percorso della cartella radice dove sono salvate le immagini.\n",
    "    - transformer (callable, opzionale): funzione o oggetto che trasforma una riga del DataFrame\n",
    "      e restituisce un dizionario con 'image' (tensore trasformato) e 'label' (bbox normalizzata).\n",
    "    - title (str, opzionale): titolo da mostrare sopra la figura.\n",
    "\n",
    "    Funzionamento:\n",
    "    - Per la prima immagine valida nel DataFrame:\n",
    "      - Carica e mostra l'immagine originale con la bounding box disegnato.\n",
    "      - Se fornito, applica la trasformazione e mostra l'immagine trasformata con bounding box aggiornata.\n",
    "    - La bounding box della trasformata √® convertita da formato YOLO (normalizzato) a coordinate pixel.\n",
    "    - Visualizza il confronto in due subplot affiancati.\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        image_path = os.path.join(dataset_path, row['image_path'])\n",
    "        if not os.path.isfile(image_path):\n",
    "            continue  # Skip silently if image missing\n",
    "\n",
    "        # Load original image and draw bbox\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        draw_orig = ImageDraw.Draw(image)\n",
    "\n",
    "        bbox = row['bbox']\n",
    "        if isinstance(bbox, str):\n",
    "            bbox = ast.literal_eval(bbox)\n",
    "\n",
    "        draw_orig.rectangle(bbox, outline='red', width=3)\n",
    "\n",
    "        if transformer:\n",
    "            sample = transformer(row)\n",
    "            if sample is None:\n",
    "                continue\n",
    "\n",
    "            transformed_img = sample['image'].permute(1, 2, 0).numpy()\n",
    "            label = sample['label'].tolist()\n",
    "            _, x_center, y_center, width, height = label\n",
    "            H, W = sample['image'].shape[1:]\n",
    "\n",
    "            # Convert YOLO bbox back to pixel coords\n",
    "            x_min = int((x_center - width / 2) * W)\n",
    "            y_min = int((y_center - height / 2) * H)\n",
    "            x_max = int((x_center + width / 2) * W)\n",
    "            y_max = int((y_center + height / 2) * H)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            axes[0].imshow(image)\n",
    "            axes[0].set_title(\"Original + BBox\")\n",
    "\n",
    "            axes[1].imshow(transformed_img)\n",
    "            axes[1].add_patch(plt.Rectangle(\n",
    "                (x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                edgecolor='red', facecolor='none', linewidth=2\n",
    "            ))\n",
    "            axes[1].set_title(\"Transformed + BBox\")\n",
    "\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(6, 6))\n",
    "            ax.imshow(image)\n",
    "            ax.set_title(\"Original\")\n",
    "\n",
    "        if title:\n",
    "            fig.suptitle(title, weight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        break  # Show only first valid example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bc344-c7bd-4c0e-b179-5d618d025d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = YoloCCPDTransformCentered(dataset_path=dataset_path)\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Mostra esempio dal TRAIN\n",
    "\n",
    "plot_ccpd_pair(train_df, dataset_path, transformer=transformer, title=\"Train Sample\")\n",
    "\n",
    "# Mostra esempio dal VAL\n",
    "plot_ccpd_pair(val_df, dataset_path, transformer=transformer, title=\"Validation Sample\")\n",
    "\n",
    "# Mostra esempio dal TEST\n",
    "plot_ccpd_pair(test_df, dataset_path, transformer=transformer, title=\"Test Sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678116a5-abfe-4864-ac99-1ef2b8e564d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def create_yolo_format(dataset_path, csv_paths, transformer, max_samples=None):\n",
    "    \"\"\"\n",
    "    Crea dataset in formato YOLOv5 compatibile con cartelle e file corretti.\n",
    "\n",
    "    Parametri:\n",
    "    - dataset_path (str): cartella radice del dataset.\n",
    "    - csv_paths (dict): dizionario con chiavi 'train', 'val', 'test' e valori i path ai csv corrispondenti.\n",
    "    - transformer (callable): funzione che applica trasformazione YoloCCPDTransformCentered,\n",
    "      riceve una riga DataFrame e restituisce dict {'image': tensore, 'label': tensore}.\n",
    "    - max_samples (dict, opzionale): dizionario con chiavi 'train', 'val', 'test' e valori il numero massimo di\n",
    "      immagini da processare per ciascuno (es. {'train': 2000, 'val': 500, 'test': 500}).\n",
    "\n",
    "    Funzionamento:\n",
    "    - Per ogni split, legge il csv e itera su ogni immagine fino a max_samples[split] se definito.\n",
    "    - Applica trasformazione.\n",
    "    - Converte l'immagine in PIL e la salva in 'YOLO_format/images/{split}/' solo se non gi√† esistente.\n",
    "    - Scrive il file label YOLO in 'YOLO_format/labels/{split}/' solo se non gi√† esistente.\n",
    "    \"\"\"\n",
    "    yolo_root = os.path.join(dataset_path, 'YOLO_format')\n",
    "    os.makedirs(yolo_root, exist_ok=True)\n",
    "\n",
    "    for split, csv_file in csv_paths.items():\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        split_img_dir = os.path.join(yolo_root, 'images', split)\n",
    "        split_label_dir = os.path.join(yolo_root, 'labels', split)\n",
    "        os.makedirs(split_img_dir, exist_ok=True)\n",
    "        os.makedirs(split_label_dir, exist_ok=True)\n",
    "\n",
    "        # Imposta il limite se definito\n",
    "        if max_samples and split in max_samples:\n",
    "            df = df.iloc[:max_samples[split]]\n",
    "\n",
    "        # Progress bar\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {split}\"):\n",
    "            img_name = os.path.basename(row['image_path'])\n",
    "            img_save_path = os.path.join(split_img_dir, img_name)\n",
    "            label_filename = os.path.splitext(img_name)[0] + '.txt'\n",
    "            label_save_path = os.path.join(split_label_dir, label_filename)\n",
    "\n",
    "            # CONTROLLO: se entrambi esistono, salta\n",
    "            if os.path.exists(img_save_path) and os.path.exists(label_save_path):\n",
    "                continue\n",
    "\n",
    "            sample = transformer(row)\n",
    "            if sample is None:\n",
    "                continue\n",
    "\n",
    "            img_pil = transforms.ToPILImage()(sample['image'].cpu())\n",
    "            img_pil.save(img_save_path)\n",
    "\n",
    "            labels = sample['label'].cpu().numpy()\n",
    "\n",
    "            # Se label ha pi√π oggetti, scriviamo tutte le righe\n",
    "            with open(label_save_path, 'w') as f:\n",
    "                if labels.ndim == 1:\n",
    "                    labels = labels.reshape(1, -1)\n",
    "\n",
    "                for obj in labels:\n",
    "                    class_id, x_center, y_center, width, height = obj\n",
    "                    f.write(f\"{int(class_id)} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    print(\" Creazione dataset in formato YOLOv5 completata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d45ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di chiamata\n",
    "transformer = YoloCCPDTransformCentered(dataset_path=dataset_path)\n",
    "csv_paths = {'train': 'train.csv', 'val': 'val.csv', 'test': 'test.csv'}\n",
    "create_yolo_format(dataset_path, csv_paths, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e46bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SPLIT .CSV:\n",
    "import pandas as pd\n",
    "\n",
    "def split_test_csv_by_directory(test_csv_path, output_dir):\n",
    "    categories = ['ccpd_blur', 'ccpd_challenge', 'ccpd_db', 'ccpd_fn',\n",
    "                  'ccpd_rotate', 'ccpd_tilt', 'ccpd_weather']\n",
    "\n",
    "    df = pd.read_csv(test_csv_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for cat in categories:\n",
    "        filtered_df = df[df['image_path'].str.split('/').str[0] == cat]\n",
    "        csv_path = os.path.join(output_dir, f\"{cat}.csv\")\n",
    "        filtered_df.to_csv(csv_path, index=False)\n",
    "        print(f\"Creato {csv_path} con {len(filtered_df)} immagini.\")\n",
    "\n",
    "split_test_csv_by_directory('test.csv',\"./csv_splits\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione dei dataset splittati per il test:\n",
    "transformer = YoloCCPDTransformCentered(dataset_path=dataset_path)\n",
    "csv_paths = {'ccpd_blur': './csv_splits/ccpd_blur.csv', 'ccpd_db': './csv_splits/ccpd_db.csv', 'ccpd_fn': './csv_splits/ccpd_fn.csv','ccpd_rotate': './csv_splits/ccpd_rotate.csv', 'ccpd_tilt': './csv_splits/ccpd_tilt.csv', 'ccpd_weather': './csv_splits/ccpd_weather.csv','ccpd_challenge':'./csv_splits/ccpd_challenge.csv'}\n",
    "create_yolo_format(dataset_path, csv_paths, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f30fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_visualize_yolo_dataset(yolo_root):\n",
    "    \"\"\"\n",
    "    Controlla la consistenza del dataset YOLOv5 e visualizza un esempio per ogni split.\n",
    "\n",
    "    Parametri:\n",
    "    - yolo_root (str): percorso della cartella principale YOLO_format contenente\n",
    "      'images/{split}/' e 'labels/{split}/'.\n",
    "\n",
    "    Funzionamento:\n",
    "    - Per ogni split ('train', 'val', 'test'):\n",
    "        - Conta il numero totale di immagini (.jpg).\n",
    "        - Verifica quante immagini hanno il file label (.txt) corrispondente.\n",
    "        - Stampa queste informazioni.\n",
    "        - Visualizza la prima immagine con label valida disegnando il bounding box.\n",
    "    - Se non sono trovate immagini con label valide in uno split, lo segnala.\n",
    "    \"\"\"\n",
    "\n",
    "    splits = ['train', 'val', 'test']\n",
    "\n",
    "    for split in splits:\n",
    "        img_dir = os.path.join(yolo_root, 'images', split)\n",
    "        label_dir = os.path.join(yolo_root, 'labels', split)\n",
    "\n",
    "        img_files = sorted(glob.glob(os.path.join(img_dir, '*.jpg')))\n",
    "        total_imgs = len(img_files)\n",
    "        valid_labels = 0\n",
    "        example_img = None\n",
    "        example_bbox = None\n",
    "\n",
    "        for img_path in img_files:\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            label_path = os.path.join(label_dir, base_name + '.txt')\n",
    "\n",
    "            if os.path.isfile(label_path):\n",
    "                valid_labels += 1\n",
    "\n",
    "                # Prendi il primo esempio con label valida\n",
    "                if example_img is None:\n",
    "                    example_img = Image.open(img_path).convert('RGB')\n",
    "                    with open(label_path, 'r') as f:\n",
    "                        line = f.readline().strip()\n",
    "                        if line:\n",
    "                            parts = line.split()\n",
    "                            x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                            w, h = example_img.size\n",
    "                            x_min = int((x_center - width / 2) * w)\n",
    "                            y_min = int((y_center - height / 2) * h)\n",
    "                            x_max = int((x_center + width / 2) * w)\n",
    "                            y_max = int((y_center + height / 2) * h)\n",
    "                            example_bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "        print(f\"Split: {split}\")\n",
    "        print(f\"Totale immagini: {total_imgs}\")\n",
    "        print(f\"Immagini con label valide: {valid_labels}\\n\")\n",
    "\n",
    "        if example_img is not None and example_bbox is not None:\n",
    "            draw = ImageDraw.Draw(example_img)\n",
    "            draw.rectangle(example_bbox, outline='red', width=3)\n",
    "\n",
    "            plt.figure(figsize=(6,6))\n",
    "            plt.imshow(example_img)\n",
    "            plt.title(f\"Esempio da {split} con bounding box\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Nessun esempio valido trovato per split {split}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_root = os.path.join(dataset_path, 'YOLO_format')\n",
    "check_and_visualize_yolo_dataset(yolo_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff29ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "# --- Configurazione percorsi ---\n",
    "repo_dir = 'yolov5'   # Modifica se serve\n",
    "weights_path = os.path.join(repo_dir, 'yolov5s.pt')  # Verifica che esista\n",
    "dataset_YOLO = 'CCPD2019/YOLO_format/images/train'  # Percorso immagini train\n",
    "\n",
    "# Aggiungi repo yolov5 al path per importare moduli interni\n",
    "sys.path.insert(0, repo_dir)\n",
    "\n",
    "# Importa modello\n",
    "from models.common import DetectMultiBackend\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carica modello\n",
    "model = DetectMultiBackend(weights_path, device=device, dnn=False)\n",
    "\n",
    "# Funzione inferenza e visualizzazione con NMS corretta\n",
    "def infer_and_plot(model, img_path, device, input_size=(640, 640), conf_thres=0.25, iou_thres=0.45):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    input_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # Inference (output raw)\n",
    "    pred = model(input_tensor)\n",
    "\n",
    "    # Importa la funzione di non max suppression dalla repo yolov5\n",
    "    from utils.general import non_max_suppression\n",
    "\n",
    "    detections = non_max_suppression(pred, conf_thres, iou_thres)[0]\n",
    "\n",
    "    print(f\"Risultati per {os.path.basename(img_path)}:\")\n",
    "    if detections is None or len(detections) == 0:\n",
    "        print(\"Nessuna predizione trovata.\")\n",
    "        return\n",
    "\n",
    "    img_cv = cv2.imread(img_path)\n",
    "    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    for *xyxy, conf, cls in detections.cpu().numpy():\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        label = f\"{model.names[int(cls)]} {conf:.2f}\"\n",
    "        cv2.rectangle(img_cv, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(img_cv, label, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img_cv)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Inferenza su prime 2 immagini\n",
    "image_files = sorted(os.listdir(dataset_YOLO))[:2]\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(dataset_YOLO, img_file)\n",
    "    infer_and_plot(model, img_path, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spostati nella cartella yolov5 ed esegui il training in un'unica riga\n",
    "!cd yolov5 && python yolov5/train.py   --img 640   --batch 25   --epochs 10   --data data.yaml   --weights yolov5s.pt   --optimizer Adam   --hyp yolov5/data/hyps/hyp.scratch-low.yaml  --name yolov5_ccpd_adam\n",
    "\n",
    "# comando per inference:\n",
    "\n",
    "python yolov5/val.py --weights best_yolo_weights.pt --data data_test.yaml --task test --batch 25 --workers 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
