{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c281184-c22e-4e98-a668-b717c2f1a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt  # Visualizzazione grafici e immagini\n",
    "import numpy as np               # Operazioni numeriche su array multidimensionali\n",
    "import os                       # Interazione con il sistema operativo (file, cartelle)\n",
    "import pandas as pd             # Manipolazione e analisi di dati tabellari (DataFrame)\n",
    "import random                   # Funzioni per generazione di numeri casuali\n",
    "import sys                      # Funzioni per interagire con l'ambiente di esecuzione Python\n",
    "import torch                    # Libreria principale di deep learning PyTorch (tensori, GPU)\n",
    "import torch.nn as nn           # Costruzione modelli di reti neurali con layer predefiniti\n",
    "import torch.nn.functional as F # Funzioni utili come attivazioni, loss, pooling\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from fvcore.nn import FlopCountAnalysis  # Analisi di FLOPS e complessita' computazionale della rete\n",
    "from IPython.display import display       # Visualizzazione ricca di output (notebook Jupyter)\n",
    "from PIL import Image, ImageDraw, ImageFont   # Manipolazione e caricamento immagini\n",
    "from torch.utils.data import Dataset, DataLoader  # Gestione dataset personalizzati e batching\n",
    "from torchvision import transforms       # Trasformazioni e preprocessamento immagini\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import accumulate as _accumulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd56421-08d1-430a-bd7e-081b537c879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(torch.version.cuda)  # Es: '12.1'\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcbb94-b680-4c84-bfdb-494f554f4c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso locale al dataset\n",
    "dataset_path = 'CCPD2019' \n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Dataset trovato in locale!\")\n",
    "else:\n",
    "    print(f\"Dataset non trovato al percorso: {dataset_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448754b-38f8-4427-b579-ce62ed169cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per decodificare la targa\n",
    "def decode_plate(plate_str):\n",
    "    \"\"\"\n",
    "    Decodifica la stringa codificata di una targa in una rappresentazione leggibile.\n",
    "\n",
    "    Parametri:\n",
    "    - plate_str (str): stringa contenente indici separati da underscore che rappresentano \n",
    "      provincia, lettere e numeri della targa.\n",
    "\n",
    "    Restituisce:\n",
    "    - str: targa decodificata come combinazione di caratteri provincia, lettere e numeri.\n",
    "    \"\"\"\n",
    "    provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\",\n",
    "                 \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\",\n",
    "                 \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "    alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P',\n",
    "                 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'O']\n",
    "    ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P',\n",
    "           'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', \n",
    "           '4', '5', '6', '7', '8', '9', 'O']\n",
    "    \n",
    "    indices = list(map(int, plate_str.split('_')))\n",
    "    prov = provinces[indices[0]] if indices[0] < len(provinces) else 'O'\n",
    "    alpha = alphabets[indices[1]] if indices[1] < len(alphabets) else 'O'\n",
    "    ads_str = ''.join(ads[i] if i < len(ads) else 'O' for i in indices[2:])\n",
    "    return prov + alpha + ads_str\n",
    "\n",
    "stringa_prova = decode_plate(\"0_1_2_3_5_4_6\")\n",
    "print(f'Prova funzione decode_plate:\\n')\n",
    "print(stringa_prova)\n",
    "\n",
    "# Funzione per analizzare il nome del file\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Analizza un nome file immagine e ne estrae informazioni strutturate.\n",
    "\n",
    "    Parametri:\n",
    "    - filename (str): nome del file immagine (es. 'area-tilt-bbox-vertices-plate-brightness-blurriness.jpg').\n",
    "\n",
    "    Restituisce:\n",
    "    - dict: dizionario con i seguenti campi:\n",
    "        - 'area' (str): area del veicolo o zona.\n",
    "        - 'tilt' (str): inclinazione.\n",
    "        - 'bbox' (list[int]): bounding box come [x_min, y_min, x_max, y_max].\n",
    "        - 'vertices' (list[list[int]]): lista di 4 punti vertici [[x1,y1], [x2,y2], ...].\n",
    "        - 'annotation' (str): targa decodificata.\n",
    "        - 'brightness' (int or None): luminosita'.\n",
    "        - 'blurriness' (int or None): sfocatura.\n",
    "\n",
    "    Lancia ValueError se il nome file non e' conforme.\n",
    "    \"\"\"\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    parts = name.split('-', maxsplit=6)  # attesi 7 campi\n",
    "    \n",
    "    if len(parts) != 7:\n",
    "        raise ValueError(f\"Filename non conforme (attesi 7 campi): {filename}\")\n",
    "    \n",
    "    area = parts[0]\n",
    "    tilt = parts[1]\n",
    "\n",
    "    # Parsing bounding box [x_min, y_min, x_max, y_max]\n",
    "    bbox_field = parts[2]\n",
    "    try:\n",
    "        leftup_str, rightdown_str = bbox_field.split('_')\n",
    "        x_min, y_min = map(int, leftup_str.split('&'))\n",
    "        x_max, y_max = map(int, rightdown_str.split('&'))\n",
    "        bbox = [x_min, y_min, x_max, y_max]\n",
    "    except Exception:\n",
    "        bbox = None\n",
    "\n",
    "    # Parsing vertici: trasformo da \"x1&y1_x2&y2_x3&y3_x4&y4\" a [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]\n",
    "    vertices_str = parts[3]\n",
    "    try:\n",
    "        vertices_points = vertices_str.split('_')\n",
    "        vertices = [list(map(int, point.split('&'))) for point in vertices_points]\n",
    "    except Exception:\n",
    "        vertices = None\n",
    "\n",
    "    plate_field = parts[4]\n",
    "    annotation = decode_plate(plate_field)\n",
    "\n",
    "    brightness = int(parts[5]) if parts[5].isdigit() else None\n",
    "    blurriness = int(parts[6]) if parts[6].isdigit() else None\n",
    "\n",
    "    return {\n",
    "        'area': area,\n",
    "        'tilt': tilt,\n",
    "        'bbox': bbox,\n",
    "        'vertices': vertices,\n",
    "        'annotation': annotation,\n",
    "        'encoded_label': plate_field,\n",
    "        'brightness': brightness,\n",
    "        'blurriness': blurriness\n",
    "    }\n",
    "\n",
    "filename_test = parse_filename(\"01-86_91-298&341_449&414-458&394_308&410_304&357_454&341-0_0_14_28_24_26_29-124-24.jpg\")\n",
    "print(f'Prova funzione parse_filename:\\n')\n",
    "print(filename_test)\n",
    "\n",
    "# Funzione crop della targa\n",
    "def crop_plate_image(row, dataset_path, size=(100, 32)):\n",
    "    \"\"\"\n",
    "    Ritaglia la bbox esatta, ridimensiona a dimensione OCR-friendly, restituisce crop PIL + label.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(dataset_path, row['image_path'])\n",
    "    if not os.path.isfile(image_path):\n",
    "        return None\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    bbox = row['bbox']\n",
    "    if isinstance(bbox, str):\n",
    "        bbox = ast.literal_eval(bbox)\n",
    "\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    crop = image.crop((x_min, y_min, x_max, y_max))\n",
    "    crop = crop.resize(size, Image.BILINEAR)\n",
    "\n",
    "    label = row['annotation']\n",
    "    return crop, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION SET\n",
    "# Dataset: carica CSV\n",
    "dataset_path = 'CCPD2019'\n",
    "df = pd.read_csv('val.csv')  # oppure val.csv o test.csv\n",
    "\n",
    "# Aggiungi bbox + annotation\n",
    "df['annotation'] = df['image_path'].apply(lambda fn: parse_filename(fn)['annotation'])\n",
    "df['bbox'] = df['image_path'].apply(lambda fn: parse_filename(fn)['bbox'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Loop: crea immagini + labels.txt, VALIDATION set\n",
    "output_dir = './data_val/onlyLP_val'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "labels_path = labels_path = './data_val/labels_val.txt'\n",
    "\n",
    "label_lines = [] # inizializzo l'array di labels\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    result = crop_plate_image(row, dataset_path)\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    crop, label = result\n",
    "\n",
    "    filename = f\"{idx:06d}.jpg\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    crop.save(output_path)\n",
    "\n",
    "    label_lines.append(f\"{filename}\\t{label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da6ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(label_lines)\n",
    "\n",
    "print(f\"[INFO] Generati {len(label_lines)} crop in '{output_dir}' e labels in '{labels_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25370eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET\n",
    "# Dataset: carica CSV\n",
    "dataset_path = 'CCPD2019'\n",
    "df = pd.read_csv('train.csv')  # oppure val.csv o test.csv\n",
    "\n",
    "# Aggiungi bbox + annotation\n",
    "df['annotation'] = df['image_path'].apply(lambda fn: parse_filename(fn)['annotation'])\n",
    "df['bbox'] = df['image_path'].apply(lambda fn: parse_filename(fn)['bbox'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Loop: crea immagini + labels.txt, VALIDATION set\n",
    "output_dir = './data_train/onlyLP_train'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "labels_path = labels_path = './data_train/labels_train.txt'\n",
    "\n",
    "label_lines = [] # inizializzo l'array di labels\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    result = crop_plate_image(row, dataset_path)\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    crop, label = result\n",
    "\n",
    "    filename = f\"{idx:06d}.jpg\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    crop.save(output_path)\n",
    "\n",
    "    label_lines.append(f\"{filename}\\t{label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(label_lines)\n",
    "\n",
    "print(f\"[INFO] Generati {len(label_lines)} crop in '{output_dir}' e labels in '{labels_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87884dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creazione di file test.csv completo\n",
    "dataset_root = 'CCPD2019'\n",
    "categorie_target = ['ccpd_blur', 'ccpd_db', 'ccpd_fn', 'ccpd_rotate', 'ccpd_tilt', 'ccpd_weather','ccpd_challenge']\n",
    "# 'ccpd_np' aggiungere questa riscaricando solo questa cartella\n",
    "\n",
    "records = []\n",
    "\n",
    "for cat in categorie_target:\n",
    "    category_dir = os.path.join(dataset_root, cat)\n",
    "    if not os.path.exists(category_dir):\n",
    "        print(f\" Directory non trovata: {category_dir}\")\n",
    "        continue\n",
    "\n",
    "    for img_file in os.listdir(category_dir):\n",
    "        if not (img_file.endswith('.jpg') or img_file.endswith('.png')):\n",
    "            continue\n",
    "\n",
    "        image_path = f\"{cat}/{img_file}\"\n",
    "        filename = os.path.basename(img_file)  # solo nome file\n",
    "        parsed = parse_filename(filename)\n",
    "\n",
    "\n",
    "        record = {\n",
    "            'image_path': image_path,\n",
    "            'area': parsed.get('area', None),\n",
    "            'tilt': parsed.get('tilt', None),\n",
    "            'bbox': parsed.get('bbox', None),\n",
    "            'vertices': parsed.get('vertices', None),\n",
    "            'annotation': parsed.get('annotation', None),\n",
    "            'encoded_label': parsed.get('encoded_label', None),\n",
    "            'brightness': parsed.get('brightness', None),\n",
    "            'blurriness': parsed.get('blurriness', None)\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Salva CSV\n",
    "df.to_csv('test.csv', index=False)\n",
    "print(f\" File test.csv salvato con {len(df)} immagini.\")\n",
    "print(df.columns)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee03fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "# Dataset: carica CSV\n",
    "dataset_path = 'CCPD2019'\n",
    "df = pd.read_csv('test.csv')  # oppure val.csv o test.csv\n",
    "\n",
    "# Aggiungi bbox + annotation\n",
    "df['annotation'] = df['image_path'].apply(lambda fn: parse_filename(fn)['annotation'])\n",
    "df['bbox'] = df['image_path'].apply(lambda fn: parse_filename(fn)['bbox'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Loop: crea immagini + labels.txt, VALIDATION set\n",
    "output_dir = './data_test/onlyLP_test'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# path del file labels:\n",
    "labels_path = './data_test/labels_test.txt'\n",
    "\n",
    "label_lines = [] # inizializzo l'array di labels\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    result = crop_plate_image(row, dataset_path)\n",
    "    if result is None:\n",
    "        continue\n",
    "\n",
    "    crop, label = result\n",
    "\n",
    "    filename = f\"{idx:06d}.jpg\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    crop.save(output_path)\n",
    "\n",
    "    label_lines.append(f\"{filename}\\t{label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27414363",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(labels_path, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(label_lines)\n",
    "\n",
    "print(f\"[INFO] Generati {len(label_lines)} crop in '{output_dir}' e labels in '{labels_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f498fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparazione della cartella TEST splittata per poi fare inference separate\n",
    "dataset_path = 'CCPD2019'\n",
    "df = pd.read_csv('test.csv', header=None, usecols=[0], names=['image_path'])\n",
    "print(df.head())\n",
    "\n",
    "categorie_target = ['ccpd_blur', 'ccpd_db', 'ccpd_fn', 'ccpd_rotate','ccpd_challenge' ,'ccpd_tilt', 'ccpd_weather']\n",
    "# 'ccpd_np'\n",
    "output_root = './data_test_split'\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "def resize_32x100(pil_img):\n",
    "    return pil_img.resize((100, 32), Image.BILINEAR)\n",
    "\n",
    "totali = {cat: 0 for cat in categorie_target}\n",
    "\n",
    "label_files = {}\n",
    "for cat in categorie_target:\n",
    "    cat_dir = os.path.join(output_root, cat)\n",
    "    data_dir = os.path.join(cat_dir, 'data')\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    label_files[cat] = open(os.path.join(cat_dir, 'labels.txt'), 'w', encoding='utf-8')\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    image_rel_path = row['image_path']\n",
    "    categoria = image_rel_path.split('/')[0]\n",
    "\n",
    "    if categoria not in categorie_target:\n",
    "        continue\n",
    "\n",
    "    image_full_path = os.path.join(dataset_path, image_rel_path)\n",
    "    if not os.path.exists(image_full_path):\n",
    "        print(f\"⚠️ Immagine non trovata: {image_full_path}\")\n",
    "        continue\n",
    "\n",
    "    image = Image.open(image_full_path).convert('RGB')\n",
    "\n",
    "    # Parsing filename per bbox e label:\n",
    "    parsed = parse_filename(image_rel_path)\n",
    "    bbox = parsed['bbox']\n",
    "    label = parsed['annotation']\n",
    "\n",
    "    # Cropping immagine\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    crop = image.crop((x1, y1, x2, y2))\n",
    "    crop = resize_32x100(crop)\n",
    "\n",
    "    filename = f\"{totali[categoria]:06d}.jpg\"\n",
    "    out_img_path = os.path.join(output_root, categoria, 'data', filename)\n",
    "    crop.save(out_img_path)\n",
    "\n",
    "    label_files[categoria].write(f\"{filename}\\t{label}\\n\")\n",
    "    totali[categoria] += 1\n",
    "\n",
    "for f in label_files.values():\n",
    "    f.close()\n",
    "\n",
    "print(\"Completato:\")\n",
    "for cat in categorie_target:\n",
    "    print(f\"{cat}: {totali[cat]} immagini salvate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_text_recognition_benchmark.dataset import AlignCollate\n",
    "# Test della funzione di augmentazione:\n",
    "\n",
    "# Percorso dataset\n",
    "dataset_path = \"./data_train/onlyLP_train\"\n",
    "\n",
    "# ---- Carica prime 3 immagini ----\n",
    "images = [f for f in os.listdir(dataset_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "images.sort()\n",
    "images = images[:3]\n",
    "\n",
    "if not images:\n",
    "    print(\" Nessuna immagine trovata nel dataset!\")\n",
    "    exit()\n",
    "\n",
    "# ---- Carica immagini con PIL ----\n",
    "pil_images = [Image.open(os.path.join(dataset_path, img)).convert(\"RGB\") for img in images]\n",
    "labels = [img.split('.')[0] for img in images]  # etichetta semplice col nome file\n",
    "\n",
    "# ---- Setup AlignCollate con augmentation attiva ----\n",
    "collate_fn = AlignCollate(imgH=32, imgW=100, keep_ratio_with_pad=True, is_training=True)\n",
    "\n",
    "# ---- Simula batch come lista di tuple (immagine, label) ----\n",
    "batch = [(img, label) for img, label in zip(pil_images, labels)]\n",
    "\n",
    "# ---- Applica AlignCollate ----\n",
    "image_tensors, augmented_labels = collate_fn(batch)\n",
    "\n",
    "print(f\" Batch generato: {image_tensors.shape}, labels: {augmented_labels}\")\n",
    "\n",
    "# ---- Visualizza originale e augmentata ----\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(3):\n",
    "    # Indici nel tensor: originale = 2i, augmentata = 2i+1\n",
    "    img_orig = image_tensors[2 * i].squeeze().permute(1, 2, 0).numpy()\n",
    "    img_aug = image_tensors[2 * i + 1].squeeze().permute(1, 2, 0).numpy()\n",
    "\n",
    "    plt.subplot(3, 2, i*2 + 1)\n",
    "    plt.imshow(img_orig, cmap='gray')\n",
    "    plt.title(f\"Orig: {labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 2, i*2 + 2)\n",
    "    plt.imshow(img_aug, cmap='gray')\n",
    "    plt.title(f\"Augm: {labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ab3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mettere il comando per generare il dataset dalla riga dei comandi:\n",
    "\n",
    "python3 deep_text_recognition_benchmark/create_lmdb_dataset.py^\n",
    "--inputPath onlyLP_test_split/ccpd_blur/data --gtFile onlyLP_test_split/ccpd_blur/labels.txt ^\n",
    "--outputPath data_test_split/ccpd_blur\n",
    "\n",
    "# in seguito creare le cartelle MJ e ST! in cui copiare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comando di allenamento:\n",
    "python3 deep_text_recognition_benchmark/train.py --train_data train_lmdb --valid_data val_lmdb ^\n",
    "--select_data MJ-ST --batch_ratio 0.5-0.5 --Transformation TPS --FeatureExtraction ResNet ^ \n",
    "--SequenceModeling BiLSTM --Prediction Attn ^\n",
    "--saved_model saved_models/TPS-ResNet-BiLSTM-Attn.pth --num_iter 10420 ^ \n",
    "--valInterval 2084 --workers 0 --data_filtering_off --batch_size 48\n",
    "\n",
    "\n",
    "# comando di test/inference:\n",
    "python3 deep_text_recognition_benchmark/test.py --eval_data val_lmdb/MJ^\n",
    "--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM ^\n",
    "--Prediction Attn --saved_model saved_models/TPS-ResNet-BiLSTM-Attn-Seed1111/best_accuracy.pth ^\n",
    "--workers 0 --data_filtering_off\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
